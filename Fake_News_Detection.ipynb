{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comparative Text Classification for Fake News Detection: An Analysis of Statistical and Deep Learning Models\n"
      ],
      "metadata": {
        "id": "o2us0-LjCTw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About the DataSet\n",
        "The dataset used for this project is publicly available on Kaggle, titled \"Fake News Detection Dataset\" by TheRealSampat. https://www.kaggle.com/code/therealsampat/fake-news-detection/notebook.\n",
        "This dataset is specifically designed for the task of classifying news articles as either \"real\" or \"fake.\" It typically comprises a collection of news articles, each labeled with its veracity. Key columns usually include:\n",
        "\n",
        "title: The headline of the news article.\n",
        "\n",
        "text: The full content or body of the news article.\n",
        "\n",
        "label: A binary indicator (e.g., 0 for real, 1 for fake, or vice versa) representing the authenticity of the news.\n",
        "\n",
        "Other metadata columns might also be present, such as subject or date, which can sometimes provide additional contextual features.\n",
        "\n",
        "The dataset is balanced, meaning it contains a roughly equal number of real and fake news articles, which is crucial for training unbiased classification models. The diversity of content, ranging from factual reporting to potentially misleading information, makes it a robust resource for developing and testing machine learning models aimed at automatically detecting deceptive content."
      ],
      "metadata": {
        "id": "C8YelL6a_7HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Introduction"
      ],
      "metadata": {
        "id": "NZD7wI6owdar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Domain-Soecific Area:** Fake News Detection\n",
        "The widespred dissemination of fake news has become a significant societal concer, particulary with the rise of digital platforms and social media. Fake news refers to intentionally fabricated content that mimics news media format but lacks the editorial standards and intent of legitimate journalism. Its presence can mislead the public, influence political decisions, and cause social unrest, as seen during events like the 2016 U.S. presidential election and the COVID-19 pandemic.\n",
        "\n",
        "  In  the field of Natural Language Processing (NLP) domain, fake news detection is a crucial classification problem, where machine learning models can be employed  to disinguish between real and fabricated news articles based of textual features. The goal is to develop automated systems capable of identitying misleading information by analyzing patterns in language use, sentence, structure, and word semantics.\n",
        "\n",
        "  Recent literature highlights the use of both traditional statistical models and modern deep learning techniques in tackling this issue. Shu et al. (2017) emphasized the need for data mining and NLP approaches in combating fake news, while Zhou and Zafarani (2018) provided a comprehensive survey of machine learning frameworks used for detection. These studies confirm that a dual approach—comparing conventional methods like TF-IDF-based classification with more sophisticated models like BERT or LSTM—can provide valuable insights into model performance across different linguistic representations.\n",
        "\n",
        "  In this project, fake news detection is formulated as a binary classification task: classifying articles as either FAKE or REAL based on their title and/ or body text. The focus will be on comparing two different modeling approaches to identify which better captures the underlying patterns of misinformation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kGIxv25DRqjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Objectives**\n",
        "\n",
        "  The primary objective of this coursework is to compare the performance of two distinct text classification paradigms for fake news detection: a statistical model and an embedding-based deep learning model.\n",
        "\n",
        "  The statistical model will utilize Term Frequency-Inverse Document Frequency(TF-IDF) vectorization combined with a Logistic Regression classifer.\n",
        "\n",
        "  The embedding-based approach will use either a Long Short-Term Memory (LSTM) neural network or a pre-trained BERT model to capture contextual and semantic features of the news articles.\n",
        "\n",
        "  This comparative study will assess the model's ability to handle:\n",
        "  -Longer and more complex text bodies,\n",
        "  -Informal, biased, or emotionally charged language typical of fake news.\n",
        "\n",
        "  The analysis aims to determine the practical strengths and limitations of each model type, offering insights into their real-world applicability i news verification systems, social media monitoring tools, and content moderation platforms.\n"
      ],
      "metadata": {
        "id": "4zRBo72uvtKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Dataset Description**\n",
        "\n",
        "  This project will use the Fake and Real News Dataset by Clement Bisaillion, available on Kaggle. The dataset contains over 23,000 news articles, evenly divided between fake and real labels. Each article entry includes fields such as title, text, subject, date and binary label indicating its aunthenticity (Fake or Real).\n",
        "\n",
        "  The dataset is well-suited for binary text classification and is balanced, which facilitates fair evaluation. For model training and evaluation, the 'text' field will be used as the primary input, although combinig the 'title' and 'text' fields may also be considered to enhance performance.\n",
        "\n",
        "  Preprocessing steps will include removing null entries, eliminating duplicate rows, lowercasing, tokenization, stopword removal, and lemmatization for the statistical model. The embedding-based model may require additional steps such as sequence padding or tokenizer encoding."
      ],
      "metadata": {
        "id": "-QR44IU2v3bO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Evaluation Methodology**\n",
        "\n",
        "  To evaluate model performance, a range of classification metrics will be applied, including Accuarcy, Precision, Recall, and F1-score. Among these, F1-Score is particularly critical due to its balanced meausrement of precision and recall, especially in cases where class imbalane might emerge.\n",
        "\n",
        "  Additional evaluation tools such as confusiin matrices and Receiver Operating Characteristic (ROC) curves will be used to visualize and interpret the model's  discrimnative capabilities. The dataset will be split using an 80/20 train-test ration or through 5-fold cross-validation to ensure robust generalization and reliable performance comparisons."
      ],
      "metadata": {
        "id": "CyboDhcHn8-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Implementation"
      ],
      "metadata": {
        "id": "v7LWkgQ3wmIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Various Cleaning Processes and Dataset-Specific Considerations\n",
        "\n",
        "Preparing the raw text data for machine learning models is a critical step due to its inherent unstructured and noisy nature. The following comprehensive preprocessing steps were applied:"
      ],
      "metadata": {
        "id": "vGQ4fWkHCmTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Data Preprocessing**"
      ],
      "metadata": {
        "id": "B4BZqnLVwuGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Understaning the data:\n",
        "   The dataset of fake and true csv file getting from the kaggle are loaded into separate the dataframses using the Pandas library\n",
        "\n",
        "*  **Initial Data Loading and Labeling:** Separate CSV files for \"Fake\" and \"True\" news were loaded into Pandas DataFrames. A label column was then explicitly added to each, assigning 0 for fake news and 1 for true news, before concatenating them into a single combined_df.\n",
        "\n"
      ],
      "metadata": {
        "id": "5HFcHfMrKjng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7QKoSphJrgd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "fake_df = pd.read_csv(\"/content/drive/MyDrive/NLP_MidTerm/Fake.csv\")\n",
        "true_df = pd.read_csv(\"/content/drive/MyDrive/NLP_MidTerm/True.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Examine the columns in each file:  The file have title, text, subject, and date. The text colimns will be the most useful for my analysis obviosuly, but the title might also be helpful."
      ],
      "metadata": {
        "id": "fxt5S3gGLKaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels\n",
        "fake_df['label'] = 0  # 0 for Fake news\n",
        "true_df['label'] = 1   # 1 for True news\n",
        "\n",
        "# Display the first few rows of each dataframe\n",
        "print(\"Fake News Data:\")\n",
        "print(fake_df.head())\n",
        "print(\"\\nTrue News Data:\")\n",
        "print(true_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_MOOgPRKNEd",
        "outputId": "fe3e92a2-3c9a-4d0d-952c-8c16f5f0cadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News Data:\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "2  On Friday, it was revealed that former Milwauk...    News   \n",
            "3  On Christmas day, Donald Trump announced that ...    News   \n",
            "4  Pope Francis used his annual Christmas Day mes...    News   \n",
            "\n",
            "                date  label  \n",
            "0  December 31, 2017      0  \n",
            "1  December 31, 2017      0  \n",
            "2  December 30, 2017      0  \n",
            "3  December 29, 2017      0  \n",
            "4  December 25, 2017      0  \n",
            "\n",
            "True News Data:\n",
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date  label  \n",
            "0  December 31, 2017       1  \n",
            "1  December 29, 2017       1  \n",
            "2  December 31, 2017       1  \n",
            "3  December 30, 2017       1  \n",
            "4  December 29, 2017       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some basic information about the dataframes\n",
        "print(\"\\nInformation about Fake News Data:\")\n",
        "print(fake_df.info())\n",
        "print(\"\\nInformation about True News Data:\")\n",
        "print(true_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMOLOzS8KU6Q",
        "outputId": "fc67462b-d562-4a6c-b6f9-c62dd92dc213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Information about Fake News Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23481 entries, 0 to 23480\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    23481 non-null  object\n",
            " 1   text     23481 non-null  object\n",
            " 2   subject  23481 non-null  object\n",
            " 3   date     23481 non-null  object\n",
            " 4   label    23481 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 917.4+ KB\n",
            "None\n",
            "\n",
            "Information about True News Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21417 entries, 0 to 21416\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    21417 non-null  object\n",
            " 1   text     21417 non-null  object\n",
            " 2   subject  21417 non-null  object\n",
            " 3   date     21417 non-null  object\n",
            " 4   label    21417 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 836.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Handling Missing Values:** Although the loaded dataframes fake_df and true_df showed no missing values in their respective columns, the project description noted the importance of \"removing null entries\" as a general preprocessing step to ensure data integrity."
      ],
      "metadata": {
        "id": "blxcNrD6Lwp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values in Fake News Data:\")\n",
        "print(fake_df.isnull().sum())\n",
        "print(\"\\nMissing values in True News Data:\")\n",
        "print(true_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2dHxP7TKX6j",
        "outputId": "dad09026-2296-4fbd-9622-822967fbcbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in Fake News Data:\n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "label      0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in True News Data:\n",
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "label      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Labeling: Need  away to distingusih between fake and true news, thus why, add a new column called label to both dataframes.\n",
        "  *    For fake csv, assign the label 0.\n",
        "  *   For true csv, assign the label 1.\n",
        "\n",
        "Combine the two dataframes into a single datafrme to complete the dataset.\n"
      ],
      "metadata": {
        "id": "rqgM4BHyL3oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing the require libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "ZzaTU2TePtOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Breakdown of the below code Combine Dataset does:\n",
        "* pd.concat(): function merges fake_df and true_df vertically like adding the rows of one DataFrame to the end of the other.\n",
        "* ignore_index_true: This ensures that the combined DataFrame has a contionous index, avoiding potential issues.\n",
        "* combined_df.sample(frac=1, random_state=42).reset_index(drop=True): This shuffle the combined DataFrame. Shuffling is very important before training a machine learning model to prevent it from learning patterns based on the order of the data. random_state ensures that getting the same shuffle everytime the code run, which is helpful for reproducibility\n"
      ],
      "metadata": {
        "id": "MUJNw5OuRtP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Combine the datasets\n",
        "combined_df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined dataset (important for training)\n",
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nCombined Dataframe:\")\n",
        "print(combined_df.head())\n",
        "print(combined_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uM0PzS7P2A4",
        "outputId": "deb26513-7715-44c7-d0c4-88970fa906e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Dataframe:\n",
            "                                               title  \\\n",
            "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
            "1  Trump drops Steve Bannon from National Securit...   \n",
            "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
            "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
            "4  Donald Trump heads for Scotland to reopen a go...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
            "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
            "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
            "3  On Monday, Donald Trump once again embarrassed...          News   \n",
            "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
            "\n",
            "                  date  label  \n",
            "0    February 13, 2017      0  \n",
            "1       April 5, 2017       1  \n",
            "2  September 27, 2017       1  \n",
            "3         May 22, 2017      0  \n",
            "4       June 24, 2016       1  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44898 entries, 0 to 44897\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    44898 non-null  object\n",
            " 1   text     44898 non-null  object\n",
            " 2   subject  44898 non-null  object\n",
            " 3   date     44898 non-null  object\n",
            " 4   label    44898 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.7+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**For statistical Model**  \n",
        "This is the crucial step. Text data needs to be cleaned and transformed before it can be used in a model. The techniques I will be used are:\n",
        "\n",
        "\n",
        "*   Cleaning:\n",
        "  \n",
        "   *   Remove punctuation and special charaters.\n",
        "   *   Convert all text to lowercase.\n",
        "   *   Remove stop words(common words like \"the\",\"a\",\"is\", etc. that don't carry much meaning)\n",
        "   *    Handle any encoding issues.\n",
        "*   Tokenization: split the text into individual words or \"token\".\n",
        "\n",
        "* Normalization:\n",
        "   * Stemming: Reduce words to their root form\n",
        "   * Lemmatization: Similar to stemming, but aims to produce original words.(eg.\"better\" to \"good\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Mwja7JvMcUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Breakdown of the below code Text Preprocessing does:\n",
        "* nltk.download('stopwords')\n",
        "nltk.download('wordnet') are the necessary resources from the Natural Language Toolkit(NLTK) library.\n",
        "* lemamatizer= WordNetLemmatizer(): Initilizes the WordNet Lemmatizer.\n",
        "* stop_words = set(stopwords.words('english')): Get the set of English stop words.\n",
        "* preprocess_text(text) function:\n",
        "  *  text.lower():Converts text to lowercase.\n",
        "  * re.sub(r '[^\\w\\s]','',text): Remove punctuation.\n",
        "  * re.sub(r'\\d+','',text):Removes digits.\n",
        "  * text.split(): Tokenizes the text(splits it into words).\n",
        "  * [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]: Lemmatize each word and removes stop words.\n",
        "  * ''.jouin(tokens): Joins the processed tokens back into a string.\n",
        "  *The isinstance(text,str) check handles potential non-string data, prevventing errors.\n",
        "  * combined_df['text'] = combined_df['text'].apply(preprocess_text): Applies the preprocess_text function to the 'text' column of the DataFrame, cleaning and normalizing the text.\n",
        " * combined_df['title'] = combined_df['title'].apply(preprocess_text): Does the same for the 'title' column."
      ],
      "metadata": {
        "id": "gCoOInpBS-AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Text Preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Ensure text is a string\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "        text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "        tokens = text.split()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''  # Return empty string for non-string values\n",
        "\n",
        "combined_df['text'] = combined_df['text'].apply(preprocess_text)\n",
        "combined_df['title'] = combined_df['title'].apply(preprocess_text)\n",
        "\n",
        "print(\"\\nProcessed Text Examples:\")\n",
        "print(combined_df[['title', 'text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go7JksvgQA_M",
        "outputId": "3fd186a2-46cc-4b35-8eca-e1849d5821d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed Text Examples:\n",
            "                                               title  \\\n",
            "0  ben stein call th circuit court committed coup...   \n",
            "1  trump drop steve bannon national security council   \n",
            "2  puerto rico expects u lift jones act shipping ...   \n",
            "3  oops trump accidentally confirmed leaked israe...   \n",
            "4      donald trump head scotland reopen golf resort   \n",
            "\n",
            "                                                text  \n",
            "0  st century wire say ben stein reputable profes...  \n",
            "1  washington reuters u president donald trump re...  \n",
            "2  reuters puerto rico governor ricardo rossello ...  \n",
            "3  monday donald trump embarrassed country accide...  \n",
            "4  glasgow scotland reuters u presidential candid...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 6.Baseline Performance\n",
        "Models can't work directly with text; so that need to convert it into numerical representation that our machine learning models can understand.\n",
        "I'll demonstrate using TF-IDF(Term Frequency-Inverse Document Frequency), which is a very common and effective technique for text classification. And Also split the data into training and testing sets.\n",
        "\n",
        "  Why I used TF-IDF:\n",
        "  * TF-IDF(Term Frequency-Inverse Document Frequency): Weights words based on how frequently they appear in a single document versus across all documents. This helps to give more importance to words that are distinctive to a particular news article.\n",
        "\n",
        "\n",
        "  For statistical models: use TF-IDF\n"
      ],
      "metadata": {
        "id": "aIcRse8oN21c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack # Needed for combining sparse matrices\n"
      ],
      "metadata": {
        "id": "_SAHFRkmVU_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Vecotrization:\n",
        "* This TfidfVectorizer class from scikit-learn converts text into TF-IDF features.\n",
        "\n",
        "* max_features=500: This limits the number of features(words) to the top 500 most frequent. can tune the parameter. Using too many features can lead to perfomance issues and overfitting.\n",
        "\n",
        "* tfidf_vectorizer.fit_transform(combined_df['text']): This does two things:\n",
        "   * fit: It learns the vocabulary and IDF(Inverse Document Frequency) from  training data.\n",
        "   * transform: It converts the text in the 'text' column into a TF-IDF matrix.\n"
      ],
      "metadata": {
        "id": "cdXvE7YLeFFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Extraction (TF-IDF)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)   #change from 10000\n",
        "tfidf_text = tfidf_vectorizer.fit_transform(combined_df['text'])\n",
        "tfidf_title = tfidf_vectorizer.fit_transform(combined_df['title']) #create TFIDF matrix for title"
      ],
      "metadata": {
        "id": "rVULH_OWdwwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* hstack: Combines the TF-IDF features from 'text' and 'title' horizontally. This is one way to incorporate both text and title information.\n"
      ],
      "metadata": {
        "id": "jvLoJ3lSinhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine TF-IDF features\n",
        "from scipy.sparse import hstack\n",
        "tfidf_combined = hstack([tfidf_text, tfidf_title])\n"
      ],
      "metadata": {
        "id": "TZoe0LgAd0uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the labels\n",
        "labels = combined_df['label']\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9viF9Jd2fm",
        "outputId": "f59f590d-31c1-44d6-e504-752b0ef85a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        0\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "44893    0\n",
            "44894    1\n",
            "44895    1\n",
            "44896    0\n",
            "44897    0\n",
            "Name: label, Length: 44898, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting:\n",
        "* train_test_split function from scikit-learn to split the data into training and testing sets.\n",
        "* test_size=0.2 means 20% of the data will be used for testing and the left of 80% for training.\n",
        "* random_state=42: Again, this ensures consistent splitting if run the code multiple times."
      ],
      "metadata": {
        "id": "IcAehVLNivxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_combined, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nFeature Extraction and Data Splitting Done!\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYrsfHwad4tv",
        "outputId": "0d236bb2-d235-4f5c-f0e2-e2b4475c8a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Extraction and Data Splitting Done!\n",
            "X_train shape: (35918, 1000)\n",
            "X_test shape: (8980, 1000)\n",
            "y_train shape: (35918,)\n",
            "y_test shape: (8980,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Breakdown of the output:\n",
        "  * X_train shape((35918, 20000) and X_text shape means trainging data has 35,918 samples (news articles) and each sample has 20,000 features(the TF-IDF values for the top 10,000 words in the text and 10,000 for the title).\n",
        "  * Similaryly, testing data(X_test) has 8,980 samples and the same number of features.\n",
        "  * The number of featuures(20,000) matches what I set in TfidfVectorizer(max_features=10000) * 2 (because I  combined text and title).\n",
        "  * y_train shape: (35918,) and y_test shape: (8980,)\n",
        "  This shows that the corresponding labels for  training and testing data. y_train contains the labels (0 or 1) for the 35,918 training articles, and y_test contains the labels for the 8,980 testing articles\n",
        "  * The number of labels matches the number of samples in X_train and X_test, which is exactly what I want.\n",
        "  * In summary: The shapes of the data indicate that the feature extraction and data splitting were performed correctly.\n",
        "  *  Now I have:\n",
        "\n",
        "    * A training set (X_train, y_train) to train  fake news detection model.\n",
        "    * A testing set (X_test, y_test) to evaluate the performance of  trained model on unseen data."
      ],
      "metadata": {
        "id": "smbibceojShr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Model Selection and Training**\n",
        "Based on the coursework description, the next step is to establish a baseline model and then implement the comparative classification methodology."
      ],
      "metadata": {
        "id": "96hO1XpxPOPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model: Multinomial Naive Bayes:"
      ],
      "metadata": {
        "id": "evPPyOdEls-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import necessary libraies: MultinomialNB for the model and accuarcy_score, classification_report for evaluation."
      ],
      "metadata": {
        "id": "UMvNkEg-mO3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "FWKOHMxZKab7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What following code does:\n",
        "\n",
        "**Initialize the model**: Creates an instance of the MulinomialNB classifier.\n",
        "\n",
        "**Trains the model:** fit(X_train, y_train) trains the Navie Bayes models using training data (the TF-IDF features and the corresponding labels)\n",
        "Makes predictions: predict(X_test) uses the trained model to predict the lables for test data.\n",
        "\n",
        "**Evaluate the model:**\n",
        "  * accuarcy_score: Calculate the overall accuarcy of the model's predictions.\n",
        "  * classification_report: Provides a more detailed evaluation, including precision, recall, F1-score for each class (fake and true) as well as overall metris.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aoTg8-A3mHLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "baseline_model = MultinomialNB()\n",
        "\n",
        "# Train the baseline model\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "baseline_predictions = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "baseline_accuracy = accuracy_score(y_test, baseline_predictions)\n",
        "print(\"Baseline Model (Multinomial Naive Bayes) Accuracy:\", baseline_accuracy)\n",
        "print(\"\\nBaseline Model (Multinomial Naive Bayes) Classification Report:\")\n",
        "print(classification_report(y_test, baseline_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfXMK1KzmClj",
        "outputId": "e9f68b8a-eba0-42ad-9ca7-774dcc7456c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model (Multinomial Naive Bayes) Accuracy: 0.9496659242761692\n",
            "\n",
            "Baseline Model (Multinomial Naive Bayes) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      4710\n",
            "           1       0.95      0.94      0.95      4270\n",
            "\n",
            "    accuracy                           0.95      8980\n",
            "   macro avg       0.95      0.95      0.95      8980\n",
            "weighted avg       0.95      0.95      0.95      8980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.  Baseline Model performance: Multinomial Naive Bayes\n",
        "The performance of the baseline model on the test set was evaluated using accuarcy and a detailed classlification report.\n",
        "\n",
        "Multinomial Naive Bayes model achieved an overall accuracy of 94.94%. This indicates that the model correctly classified approximately 94.94% of the news articles in the test set.\n",
        "\n",
        "The classification report provides a more granular view of the model's performance for each class:\n",
        "\n",
        "**Fake News (Class 0)**: The model achieved a precision of 0.95, recall of 0.95, and an F1-score of 0.95. This demonstrates that the model is effective at correctly identifying fake news articles with minimal false positives and false negatives.\n",
        "**True News (Class 1)**: The model obtained a precision of 0.95, recall of 0.94, and an F1-score of 0.95 for true news articles. These results are comparable to the fake news classification metrics, indicating a balanced performance across both classes.\n",
        "\n",
        "\n",
        "In conclusion, the Multinomial Naive Bayes baseline model demonstrated strong performance in classifying fake and true news, achieving high accuracy and balanced precision and recall for both classes. These results establish a solid foundation for evaluating the effectiveness of more complex models implemented in this study.\n"
      ],
      "metadata": {
        "id": "cGtnzeAzwfAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Comparative Classification\n",
        "##Model  1: Statistical Model: (Logistic Regression with TF-IDF)"
      ],
      "metadata": {
        "id": "iqkh4lkPzMTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logistic_regression_model = LogisticRegression(max_iter=1000, random_state=42)  # Increase max_iter if needed\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "logistic_regression_predictions = logistic_regression_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)\n",
        "print(\"\\nModel 1: Logistic Regression Accuracy:\", logistic_regression_accuracy)\n",
        "print(\"\\nModel 1: Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logistic_regression_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNxxhvDnmExS",
        "outputId": "02dd8b31-1afc-434e-c667-247578415eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model 1: Logistic Regression Accuracy: 0.9903118040089087\n",
            "\n",
            "Model 1: Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4710\n",
            "           1       0.99      0.99      0.99      4270\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparative Classification Methodology: Model 1 (Traditional - Logistic Regression)\n",
        "\n",
        "A Logistic Regression model was implemented as the first comparative classifier. This traditional machine learning model was trained on the same TF-IDF vectorized text data as the baseline, maintaining the 80/20 train-test split. The model's performance was evaluated using accuracy, precision, recall, and F1-score on the unseen test set.\n",
        "\n",
        "The Logistic Regression model achieved a remarkable overall accuarcy of 99.19%. This represents a significant improvement over the Multinomial Naive Bayes baseline model (which had an accuarcy of 94.94%)\n",
        "\n",
        "The detailed classification report further highlights the model's strong performance across both classes:\n",
        "\n",
        "* Fake News (Class 0): The model demonstrated excellent performance for fake news detection, with a precision of 0.99, recall of 0.99, and an F1-score of 0.99. This indicates a very high rate of correctly identified fake news articles with minimal misclassifications.\n",
        "*\n",
        "True News (Class 1): Similarly, for true news articles, the model achieved a precision of 0.99, recall of 0.99, and an F1-score of 0.99. This consistent high performance across both classes suggests that the Logistic Regression model is highly effective and balanced in its classification capabilities.\n",
        "\n",
        "\n",
        "Discussion:\n",
        "\n",
        "The Logistic Regression model significantly outperforms the Multinomial Naive Bayes baseline across all key metrics. Its near-perfect precision, recall, and F1-scores for both fake and true news categories indicate that Logistic Regression, when applied to TF-IDF features, is a highly robust and accurate traditional machine learning approach for this fake news detection task. This strong performance sets a high benchmark for the subsequent deep learning model."
      ],
      "metadata": {
        "id": "C8qrB_Tb0L_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Embedding-based Model: Deep Learning (LSTM-based classifier)"
      ],
      "metadata": {
        "id": "PvySpMI3zfTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part involve a few more steps since deep learning models require the text data to be in a specific numerical format.\n"
      ],
      "metadata": {
        "id": "-Qg1_IorCR9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code imports the necessary Python libraries to build and train a deep learning model, specifically an LSTM-based classifier, for fake news detection.\n",
        "* import tensorflow as tf: This line imports the TensorFlow library, which is a powerful open-source platform for building and training machine learning models, especially neural networks. It's aliased as tf for convenience.\n",
        "* from tensorflow.keras.preprocessing.text import Tokenizer: This imports the Tokenizer class from TensorFlow's Keras API. The Tokenizer is used to prepare text data for neural networks. It converts text into sequences of integers, where each integer represents a word.\n",
        "* from tensorflow.keras.preprocessing.sequence import pad_sequences: This imports the pad_sequences function. Deep learning models, particularly LSTMs, require input sequences to have a uniform length. This function is used to pad (add zeros to) or truncate (cut off) sequences to a specified maximum length.\n",
        "* from tensorflow.keras.models import Sequential: This imports the Sequential model class from Keras. A Sequential model is a linear stack of layers, which is a common and easy way to build neural networks.\n",
        "* from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout: This line imports several essential layer types used in building the neural network:\n",
        "Embedding: This layer is used to create dense vector representations (embeddings) of words. It maps each integer word token to a fixed-size vector that captures semantic relationships.\n",
        "LSTM: This stands for Long Short-Term Memory. LSTM layers are a type of recurrent neural network (RNN) that are particularly well-suited for processing sequential data like text, as they can remember information over long sequences.\n",
        "Dense: This represents a fully connected neural network layer, where each neuron in the layer is connected to every neuron in the previous layer.\n",
        "Dropout: This is a regularization technique where a random percentage of neurons are ignored during training. This helps prevent the model from overfitting to the training data.\n",
        "* from sklearn.model_selection import train_test_split: This imports the train_test_split function from the scikit-learn library. Although not directly used in the model building part itself, it's crucial for splitting the data into training and testing sets before feeding it to the neural network.\n",
        "* import pandas as pd: This imports the pandas library, which is widely used for data manipulation and analysis. It's used earlier in the notebook to load and process the dataset. [3]\n",
        "\n",
        "\n",
        "These imported libraries provide the building blocks for creating, preparing data for, training, and evaluating the deep learning model for the fake news detection task."
      ],
      "metadata": {
        "id": "GK_m_K1xHJTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gwFACItwzbC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the *original* text data and labels into training and testing sets\n",
        "# Use the text column directly from the combined_df before TF-IDF transformation\n",
        "X_train_text, X_test_text, y_train_dl, y_test_dl = train_test_split(\n",
        "    combined_df['text'], combined_df['label'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "vg2ysXd_C1Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Explanation:\n",
        "\n",
        "  1. Tokenization and Sequencing:\n",
        "  Tokenizer: This Keras class converts text into sequences of integers.\n",
        "  num_words=max_vocab: Keeps only the top max_vocab most frequent words.\n",
        "  oov_token=\"<OOV>\": Assigns the \"&lt;OOV>\" token to out-of-vocabulary words.\n",
        "  tokenizer.fit_on_texts(X_train['text']): Trains the tokenizer on  training text data. It learns the vocabulary.\n",
        "  X_train_sequences = tokenizer.texts_to_sequences(X_train['text']): Converts the training text to sequences of integers, where each integer represents a word.\n",
        "  We do the same for the test set.\n",
        "  pad_sequences: Ensures that all sequences have the same length. LSTM networks require inputs to have a consistent shape.\n",
        "  maxlen=max_length: Sets the maximum length of all sequences. Sequences longer than this are truncated, and shorter ones are padded.\n",
        "  truncating='post' and padding='post' : Specifies that truncation and padding are applied at the end of the sequences."
      ],
      "metadata": {
        "id": "7n041HblD5CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tokenization and Sequencing\n",
        "\n",
        "max_vocab = 10000  # Maximum number of words in the vocabulary\n",
        "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\")  # Initialize tokenizer\n",
        "\n",
        "# Train the tokenizer on the training text data\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "word_index = tokenizer.word_index # Save word index for reference\n",
        "\n",
        "\n",
        "# Convert texts to sequences for both training and testing sets\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "max_length = 200 # Maximum sequence length.\n",
        "\n",
        "# Pad sequences for training and testing sets\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, truncating='post', padding='post') # Also pad X_test\n",
        "\n",
        "print(\"\\nTokenization and Sequencing Done!\")\n",
        "print(\"X_train_padded shape:\", X_train_padded.shape)\n",
        "print(\"X_test_padded shape:\", X_test_padded.shape)\n",
        "print(\"y_train_dl shape:\", y_train_dl.shape)\n",
        "print(\"y_test_dl shape:\", y_test_dl.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9AXO3ZdCQmm",
        "outputId": "d02a7329-6274-43b6-c740-e9d12a96a52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization and Sequencing Done!\n",
            "X_train_padded shape: (35918, 200)\n",
            "X_test_padded shape: (8980, 200)\n",
            "y_train_dl shape: (35918,)\n",
            "y_test_dl shape: (8980,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Built the LSTM model:\n",
        "  * Sequential: Creates a sequential model(Layers are arranged in a simple stack).\n",
        "  * Embedding: This is the first layer. It coverts the integer word tokens into dense vectors(word embeddings).\n",
        "    * max_vocab: The size of vocab\n",
        "    * embedding_dim: The dimensionality of the word embeddings(how many dimensions to represent each word)\n",
        "    * input_length=max_length: The length of the input sequences.\n",
        "\n",
        "  * LSTM: Long Short-Term Mermory layer, a type of recurrent neural network (RNN) good at processing sequential data.\n",
        "   * 128,64 : Number of units in the LSTM layers.\n",
        "   * dropout=0.2, recurrent_dropout=0.2: Dropout is a regularization technique to prevent overfitting. recurrent_dropout is specific to LSTM layers.\n",
        "   * return_sequences=TrueL Important for stacking LSTM layers. It makes the first LSTM layer output a sequence for each word, which is what the next LSTM layer expects as input.\n",
        "  * Dense: A fully connected layer.\n",
        "   *  64, activation='relu':  A dense layer with 64 units and ReLU activcation.\n",
        "   * 1, activation='sigmoid': The final output layer. Since this is binary classification (fake or true), we use one unit and the sigmoid activation function to get a probability between 0 and 1.\n",
        "  * Dropout(0.5): Another dropout layer for regularization."
      ],
      "metadata": {
        "id": "n1uyLI8PL8En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# 2. Build the LSTM Model\n",
        "embedding_dim = 128  # Dimension of the word embeddings\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(max_vocab, embedding_dim, input_length=max_length),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True), # First LSTM layer\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),  # Second LSTM layer\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "\n",
        "# *** NEW CODE TO BUILD THE MODEL BEFORE SUMMARY ***\n",
        "# Create a dummy input (a single batch of the correct shape)\n",
        "dummy_input = np.zeros((1, max_length))  # Batch size 1, sequence length max_length\n",
        "\n",
        "# Pass the dummy input through the model to build it\n",
        "model.build(dummy_input.shape)  # Use .build for Sequential model"
      ],
      "metadata": {
        "id": "4v7wZe1FCfpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Complie and Train the model:\n",
        "  * model.compile(..): Configures the model for training.\n",
        "    * optimizer='binary_crossentropy': The appropriate loss function for binary classification.\n",
        "    * metrics=['accuarcy']: We'll track accuarcy during training.\n",
        "  * model.fit(..) :Trains the Model.\n",
        "    * ephochs=5: Number of times to iterate over the entire training dataset.\n",
        "    * batch_size=64: Number of samples per gradient update.\n",
        "\n",
        "    * validation_data=(X_test_padded, y_test): Evaluates the model on the test set after each epoch to monitor performance and prevent overfitting.\n",
        "\n",
        "\n",
        "\n",
        "4. Evaluate the Model:\n",
        " * model.evaluate(...): Evaluate the trained mode; on the test data and returns the loss and accuarcy.\n",
        " * classification_report, confusion_matrix: Provides more detailed evaluation metrics.\n",
        "    * y_pred_dl=model.predict(X_test_padded): Gets the model's predictions (probabilities).\n",
        "    * np.round(..):Converts probabilities to binary predictions(0 or 1)\n"
      ],
      "metadata": {
        "id": "SI_epNwEKF8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Compile and Train the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "#4 Train and Evaluate the Model\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "history = model.fit(X_train_padded, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_dl)) # Use the correct y)train_dl and y_test_dl\n",
        "\n",
        "# 4. Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test_dl)  #Use the correct y_test_dl\n",
        "print(\"\\nDeep Learning Model (LSTM) Accuracy:\", accuracy)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred_dl = model.predict(X_test_padded)\n",
        "y_pred_dl = np.round(y_pred_dl).astype(int)\n",
        "print(\"\\nDeep Learning Model (LSTM) Classification Report:\")\n",
        "print(classification_report(y_test_dl, y_pred_dl))  #Use the correct y_test_dl\n",
        "\n",
        "print(\"\\nDeep Learning Model (LSTM) Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_dl, y_pred_dl))   #Use the correct y_test_dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "SiVAGHMkDg4I",
        "outputId": "9c3d30c6-33d7-4095-a62e-62f67a46a247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,465,217\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,465,217</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,465,217\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,465,217</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 1s/step - accuracy: 0.7730 - loss: 0.4814 - val_accuracy: 0.8720 - val_loss: 0.3500\n",
            "Epoch 2/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 1s/step - accuracy: 0.8854 - loss: 0.3186 - val_accuracy: 0.9674 - val_loss: 0.1437\n",
            "Epoch 3/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m789s\u001b[0m 1s/step - accuracy: 0.9689 - loss: 0.1183 - val_accuracy: 0.9913 - val_loss: 0.0387\n",
            "Epoch 4/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m781s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 0.0261 - val_accuracy: 0.9953 - val_loss: 0.0199\n",
            "Epoch 5/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0198 - val_accuracy: 0.9962 - val_loss: 0.0135\n",
            "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 210ms/step - accuracy: 0.9957 - loss: 0.0140\n",
            "\n",
            "Deep Learning Model (LSTM) Accuracy: 0.9962137937545776\n",
            "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 213ms/step\n",
            "\n",
            "Deep Learning Model (LSTM) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      4710\n",
            "           1       0.99      1.00      1.00      4270\n",
            "\n",
            "    accuracy                           1.00      8980\n",
            "   macro avg       1.00      1.00      1.00      8980\n",
            "weighted avg       1.00      1.00      1.00      8980\n",
            "\n",
            "\n",
            "Deep Learning Model (LSTM) Confusion Matrix:\n",
            "[[4686   24]\n",
            " [  10 4260]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. CONCLUSIONS"
      ],
      "metadata": {
        "id": "dgEVGNJkpoB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Performance Analysis"
      ],
      "metadata": {
        "id": "S1hEvXftpsDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparative Classification Methodology: Model 1 (Traditional - Logistic Regression) with Reduced Features**\n",
        "\n",
        "Following the initial baseline and the previois Logistic Regression model, this section presents the performance of a Logistic Regression classifier when the TF-IDF feature extraction was performed with a reduced max_features setting of 500 for both text and title (resulting in a total of 1000 features). The model was trained on the same 80/20 train-test split.\n",
        "\n",
        "The Logistic Regression model, with max_features=500, achieved an overall accuracy of 98.42%. While still a very high accuracy, this represents a slight decrease compared to the 99.19% accuracy achieved when using max_features=10000.\n",
        "\n",
        "The detailed classification report provides further insights:\n",
        "\n",
        "* Fake News (Class 0): The model maintained strong performance for fake news, with a precision of 0.99, recall of 0.98, and an F1-score of 0.98. These metrics are slightly lower than the perfect scores observed with the larger feature set but still indicate robust detection capabilities.\n",
        "\n",
        "* True News (Class 1): For true news articles, the model achieved a precision of 0.98, recall of 0.99, and an F1-score of 0.98. Similar to class 0, there's a marginal decrease in performance compared to the max_features=10000 setup, but the performance remains excellent\n",
        "\n",
        "* Discussion:\n",
        "The reduction in max_features from 10,000 to 500 for TF-IDF features resulted in a marginal, but noticeable, decrease in the Logistic Regression model's accuracy and F1-scores. This suggests that while a smaller vocabulary still captures significant discriminatory information, the broader set of features (from the top 10,000 words) provided slightly more predictive power for this specific task. The model, however, remains highly effective, demonstrating that Logistic Regression is robust even with a more constrained feature set."
      ],
      "metadata": {
        "id": "sbXAx9Pdzij_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparative Classification Methodology: Model 2 (Deep Learning - LSTM-based Classifier)**\n",
        "\n",
        "For the deep learning approach, an LSTM-based neural network was developed. This model directly processes the sequence of word embeddings, allowing it to capture contextual relationships and dependencies within the text. Prior to model training, the text data was tokenized and padded to ensure uniform input length.\n",
        "* Embedding Layer: Converts word indices into dense 128-dimensional vectors, learning meaningful representations for each word.\n",
        "* LSTM Layers: Two stacked LSTM layers (128 units, then 64 units) are used to process the sequential nature of the text, capturing long-range dependencies. Dropout was applied to mitigate overfitting.\n",
        "* Dense Layers: Followed by a ReLU-activated Dense layer (64 units) for feature transformation and a final sigmoid-activated Dense layer (1 unit) for binary classification output (probability of being true news).\n",
        "\n",
        "**Training and Performance:**\n",
        "The model was compiled with the Adam optimizer and binary cross-entropy loss. It was trained for 5 epochs with a batch size of 64. The training history showed rapid convergence, with both training and validation accuracy steadily increasing and loss decreasing across epochs.\n",
        "\n",
        "The LSTM model achieved an exceptional overall accuracy of 99.81% on the test set.\n",
        "\n",
        "The classification report indicates near-perfect performance:\n",
        "* Fake News (Class 0): The model achieved a precision of 1.00, recall of 1.00, and an F1-score of 1.00.\n",
        "* True News (Class 1): Similarly, for true news, the model obtained a precision of 1.00, recall of 1.00, and an F1-score of 1.00.\n",
        "\n",
        "The model correctly classified 4703 fake news articles and 4260 true news articles. It made only 7 false positive errors (predicting true news when it was fake) and 10 false negative errors (predicting fake news when it was true). The near-perfect scores in the classification report reflect these very low error counts.\n",
        "\n",
        "**Discussion:**\n",
        "The deep learning LSTM model significantly surpassed both the Multinomial Naive Bayes baseline and the Logistic Regression model (even with max_features=10000), achieving the highest accuracy and F1-scores across all models tested. Its ability to learn complex patterns and contextual information from word embeddings proved highly effective for this fake news detection task. The extremely low number of misclassifications, as shown in the confusion matrix, highlights its robust and reliable performance. This outcome validates the effectiveness of deep learning approaches for advanced text classification problems."
      ],
      "metadata": {
        "id": "zhr3XfVV10Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # Needed for potential future calculations if not already imported\n",
        "\n",
        "# --- Assumed Metrics from Previous Model Runs ---\n",
        "# These values would typically come directly from  trained models' evaluation results.\n",
        "# For this code snippet, we'll use the values obtained from  previous successful runs.\n",
        "\n",
        "# Metrics for Logistic Regression (with max_features=10000, as it was the best LR performance)\n",
        "lr_accuracy = 0.9919\n",
        "lr_precision = 0.99\n",
        "lr_recall = 0.99\n",
        "lr_f1 = 0.99\n",
        "\n",
        "# Metrics for LSTM Model\n",
        "lstm_accuracy = 0.9981\n",
        "lstm_precision = 1.00 # Assuming 1.00 based on previous classification report\n",
        "lstm_recall = 1.00    # Assuming 1.00 based on previous classification report\n",
        "lstm_f1 = 1.00        # Assuming 1.00 based on previous classification report\n",
        "\n",
        "# --- 1. Collect and Prepare Data for Visualization ---\n",
        "\n",
        "# Create a dictionary to hold the metrics for each model\n",
        "metrics_data = {\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'], # Types of metrics\n",
        "    'Logistic Regression': [lr_accuracy, lr_precision, lr_recall, lr_f1], # Scores for LR\n",
        "    'LSTM': [lstm_accuracy, lstm_precision, lstm_recall, lstm_f1] # Scores for LSTM\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a Pandas DataFrame\n",
        "df_metrics = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Reshape the DataFrame from a \"wide\" format to a \"long\" format.\n",
        "# This is ideal for seaborn's barplot, where 'hue' differentiates models.\n",
        "df_metrics_melted = df_metrics.melt(id_vars='Metric', var_name='Model', value_name='Score')\n",
        "\n",
        "print(\"Data prepared for visualization:\")\n",
        "print(df_metrics_melted)\n",
        "\n",
        "# --- 2. Generate Comparative Bar Chart ---\n",
        "\n",
        "# Set the figure size for better readability of the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the bar chart using seaborn.\n",
        "# x-axis: Metric type (Accuracy, Precision, etc.)\n",
        "# y-axis: Score (the performance value)\n",
        "# hue: Differentiates bars by Model (Logistic Regression vs. LSTM)\n",
        "# palette: Color scheme for the bars\n",
        "sns.barplot(x='Metric', y='Score', hue='Model', data=df_metrics_melted, palette='viridis')\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title('Comparison of Logistic Regression and LSTM Model Performance', fontsize=16)\n",
        "\n",
        "# Add labels to the axes\n",
        "plt.ylabel('Score', fontsize=12)\n",
        "plt.xlabel('Metric', fontsize=12)\n",
        "\n",
        "# Set the y-axis limits to clearly show the small differences between high-performing models.\n",
        "# Starting from 0.90 makes the differences more apparent.\n",
        "plt.ylim(0.90, 1.00)\n",
        "\n",
        "# Add a horizontal grid for easier reading of the scores\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add a legend to identify which color corresponds to which model\n",
        "plt.legend(title='Model', fontsize=10, title_fontsize='12')\n",
        "\n",
        "# Adjust plot layout to prevent labels/titles from overlapping\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nComparative bar chart generated successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "hz_JDLkM5gab",
        "outputId": "64a9ee41-bc17-4b3f-efd4-e823c7f5d950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prepared for visualization:\n",
            "      Metric                Model   Score\n",
            "0   Accuracy  Logistic Regression  0.9919\n",
            "1  Precision  Logistic Regression  0.9900\n",
            "2     Recall  Logistic Regression  0.9900\n",
            "3   F1-score  Logistic Regression  0.9900\n",
            "4   Accuracy                 LSTM  0.9981\n",
            "5  Precision                 LSTM  1.0000\n",
            "6     Recall                 LSTM  1.0000\n",
            "7   F1-score                 LSTM  1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparative bar chart generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Comparison and conclusion:\n",
        "While both models are highly effective, the LSTM model marginally outperforms the Logistic Regression Model. This indicated that for tasks involving complex lingusitic nuances, deep learning architectures like LSTMs can provide a slight edge by understanding semantic realtionships and context beyond simple word frequencies. Howeverm the strong performance of Logistic Regression also highlights its efficiency and effectiveness as a robust baseline for text classification. The minial difference between the two models suggests that the dataset is relatively separable given the chosen preprocessing and feature engineering, but the LSTM's ability to achieve virtually perfect scroes on this dataset underscores its powerful learning capabilities."
      ],
      "metadata": {
        "id": "LdDEIiXE6yYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Project Summary and Reflections\n",
        "\n",
        "This project focused on developing and comparing text classification models for fake news detection, leveraging a dataset comprising both geniine and fabricated news articles. The primary objective was to access the effectiveness of traditional statistical models against modern deep learning approaches in accurately identifying misinformation.\n",
        "\n",
        "The metholodogy involved several key stages. Initially, comprehensive data preprocessing was performed on raw text data,including lowercasing, punctuation and digit removal, tokenization, lemmatization, and stop word removal. This cleaning step was crucial for preparing the text for subsequent machine learning.\n",
        "\n",
        "For feature extraction, two distinct approaches were employed. Traditional models utilized TF-IDF (Term Frequency-Inverse Document Frequency) vectorization, transforming text into numerical feature vectors that emphasize the importance of words within documents relative to the entire corpus. For the deep learning model, raw text sequences were tokenized and padded, with an embedding layer then converting these integer sequences into dense, semantic vector representations.\n",
        "\n",
        "A comparative analysis was conducted across three model types:\n",
        "\n",
        "* Mutlinomial Naive Bayes(Baseline): This simple probabilistic model served as a strong baseline, demonstrating good initial performance in classifying news articles.\n",
        "* Logistic Regression (Tradional Model): When applied to the rich TF-IDF features, Logistic Regression significantly surpassed the baseline, achieving high accurarcy, precision, recall, and F1-scores. This highlighted the robust capabilities of trational linear models on structured textual features.\n",
        "* LSTM (Deep Learning Model): The Long Short-Term Memory neural network, leveraging learned word embeddings, exhibited the highest performance among all tested models. Its ability to process sequential data and capture long-range dependencies allowed it to achieve near-perfect accuracy and F1-scores, demonstrating the superior representational power of deep learning for complex text understanding tasks.\n",
        "\n",
        "\n",
        "In reflection, this project underscored the critical importance of meticulous data preprocessing in natural language processing. It confirmed that while traditional machine learning models like Logistic Regression can achieve remarkable performance with effective feature engineering, deep learning architectures, such as LSTMs, offer a slight but consistent edge in accuracy, particularly by learning richer, contextual representations of text.\n",
        "\n",
        "**Key Observations and Practical Considerations for Deep Learning:**\n",
        "\n",
        "* Training Time: A significant observation was the substantial training time required for the deep learning model compared to traditional machine learning models. The LSTM model took nearly an hour to train, highlighting the computational intensity of neural networks.\n",
        "* Overfitting: Deep learning models, by nature, are prone to overfitting, given their high capacity. Techniques such as dropout layers, which were implemented in our LSTM architecture, and careful monitoring of validation performance, proved crucial in mitigating this risk and ensuring good generalization to unseen data.\n",
        "* GPU Utilization: For faster training of deep learning models, the availability and utilization of a Graphics Processing Unit (GPU) are essential. Without GPU acceleration, the training times observed would be even longer, making iterative model development impractical.\n",
        "Future work could involve exploring more sophisticated deep learning models (e.g., Transformer-based architectures like BERT), incorporating external metadata (e.g., source credibility, author reputation), or focusing on explainable AI techniques to understand why a model classifies a piece of news as fake or true."
      ],
      "metadata": {
        "id": "3rn64TPH3d35"
      }
    }
  ]
}